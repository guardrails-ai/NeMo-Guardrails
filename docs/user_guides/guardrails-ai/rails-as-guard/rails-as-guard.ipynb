{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardrails as Guards\n",
    "This guide will teach you how to add NeMo Guardrails to a GuardrailsAI Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init: remove any existing configuration\n",
    "!rm -r config\n",
    "!mkdir config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "We'll be using an OpenAI model for our LLM in this guide, so set up an OpenAI API key, if not already set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENAI_API_KEY=$OPENAI_API_KEY    # Replace with your own key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this inside a notebook, you also need to patch the AsyncIO loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Guardrails\n",
    "We'll start by creating a new guardrails configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config/config.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/config.yml\n",
    "models:\n",
    " - type: main\n",
    "   engine: openai\n",
    "   model: gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do a quick test to make sure everything is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678eabd807f642e8861d842c0eec8494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from nemoguardrails import RailsConfig, LLMRails\n",
    "\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "response = rails.generate(\"Hello!\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked!  Now let's install a validator from the GuardrailsAI Hub to augment our guardrails configuration from above.\n",
    "\n",
    "If you haven't already, install and configure guardrails-ai before trying to install the DetectPII validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install guardrails-ai\n",
    "! guardrails configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mdetect_pii...\u001b[0m\n",
      "\u001b[2K\u001b[32m[   =]\u001b[0m Fetching manifestst\n",
      "\u001b[2K\u001b[32m[   =]\u001b[0m Downloading dependenciespendencies\n",
      "\u001b[1A\u001b[2Kâœ…Successfully installed guardrails/detect_pii version \u001b[1;36m0.0\u001b[0m.\u001b[1;36m5\u001b[0m!\n",
      "\n",
      "\n",
      "\u001b[1mImport validator:\u001b[0m\n",
      "from guardrails.hub import DetectPII\n",
      "\n",
      "\u001b[1mGet more info:\u001b[0m\n",
      "\u001b[4;94mhttps://hub.guardrailsai.com/validator/guardrails/detect_pii\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! guardrails hub install hub://guardrails/detect_pii --no-install-local-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the rails defined earlier as the basis for our Guard.  We'll also attach the DetectPII validator as an additional measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NemoguardrailsGuard(id='OJLHPH', name='gr-OJLHPH', description=None, validators=[ValidatorReference(id='guardrails/detect_pii', on='$', on_fail='fix', args=None, kwargs={'pii_entities': ['PERSON', 'EMAIL_ADDRESS']})], output_schema=ModelSchema(definitions=None, dependencies=None, anchor=None, ref=None, dynamic_ref=None, dynamic_anchor=None, vocabulary=None, comment=None, defs=None, prefix_items=None, items=None, contains=None, additional_properties=None, properties=None, pattern_properties=None, dependent_schemas=None, property_names=None, var_if=None, then=None, var_else=None, all_of=None, any_of=None, one_of=None, var_not=None, unevaluated_items=None, unevaluated_properties=None, multiple_of=None, maximum=None, exclusive_maximum=None, minimum=None, exclusive_minimum=None, max_length=None, min_length=None, pattern=None, max_items=None, min_items=None, unique_items=None, max_contains=None, min_contains=None, max_properties=None, min_properties=None, required=None, dependent_required=None, const=None, enum=None, type=ValidationType(anyof_schema_1_validator=None, anyof_schema_2_validator=None, actual_instance=<SimpleTypes.STRING: 'string'>, any_of_schemas={'List[SimpleTypes]', 'SimpleTypes'}), title=None, description=None, default=None, deprecated=None, read_only=None, write_only=None, examples=None, format=None, content_media_type=None, content_encoding=None, content_schema=None), history=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from guardrails.integrations.nemoguardrails import NemoguardrailsGuard\n",
    "from guardrails.hub import DetectPII\n",
    "\n",
    "\n",
    "guard = NemoguardrailsGuard(rails)\n",
    "guard.use(DetectPII(\n",
    "    pii_entities=[\"PERSON\", \"EMAIL_ADDRESS\"],\n",
    "    on_fail=\"fix\"\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "With everything configured, we can test out our new Guard!\n",
    "\n",
    "Let's invoke the Guard with a message that prompts the LLM to return personal information like names, email addresses, etc.. Since we specified `on_fail=\"fix\"` in the DetectPII validator, the response should have any PII filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current president of the United States is <PERSON>. His official email address is <EMAIL_ADDRESS>.\n"
     ]
    }
   ],
   "source": [
    "response = guard(\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Who is the current president of the United States, and what was their email address?\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response.validated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can see that the Guard called the LLM configured in the LLMRails, validated the output, and filtered it accordingly. If however, we prompt the LLM with a message that does not cause it to return PII, we should get the unaltered response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "response = guard(\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello!\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(response.validated_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
