{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda9eda8b4566a0d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Guard as Actions\n",
    "\n",
    "This guide will teach you how to use a `Guard` with any of the 60+ GuardrailsAI Validators as an action inside a guardrails configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddc8b17af62afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:27:11.284164Z",
     "start_time": "2024-01-25T14:27:11.025161Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Init: remove any existing configuration\n",
    "! rm -r config\n",
    "! mkdir config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724db36201c3d409",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "We'll be using an OpenAI model for our LLM in this guide, so set up an OpenAI API key, if not already set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52b23b90077cf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:27:11.418023Z",
     "start_time": "2024-01-25T14:27:11.286549Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! export OPENAI_API_KEY=$OPENAI_API_KEY    # Replace with your own key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6fb59034bcb2bb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you're running this inside a notebook, you also need to patch the AsyncIO loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba19d5c8bdc57a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:27:13.693091Z",
     "start_time": "2024-01-25T14:27:13.686555Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b27d3fa09bbe91",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Sample Guard\n",
    "\n",
    "Let's create a sample Guard that can detect PII.  First, install guardrails-ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install guardrails-ai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8fc267",
   "metadata": {},
   "source": [
    "Next configure the guardrails cli so we can install the validator we want to use from the Guardrails Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "! guardrails configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a208f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! guardrails hub install hub://guardrails/detect_pii --no-install-local-models -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4fff5",
   "metadata": {},
   "source": [
    "Now we can define our Guard.\n",
    "This Guard will use the DetectPII validator to safeguard against leaking personally identifiable information such as names, email addresses, etc..\n",
    "\n",
    "Once the Guard is defined, we can test it with a static value to make sure it's working how we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71aeb10e5fda9040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:27:13.813566Z",
     "start_time": "2024-01-25T14:27:13.693010Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValidationOutcome(\n",
      "    call_id='14534730096',\n",
      "    raw_llm_output='My name is John Doe',\n",
      "    validation_summaries=[\n",
      "        ValidationSummary(\n",
      "            validator_name='DetectPII',\n",
      "            validator_status='fail',\n",
      "            property_path='$',\n",
      "            failure_reason='The following text in your response contains PII:\\nMy name is John Doe',\n",
      "            error_spans=[\n",
      "                ErrorSpan(start=11, end=19, reason='PII detected in John Doe')\n",
      "            ]\n",
      "        )\n",
      "    ],\n",
      "    validated_output='My name is <PERSON>',\n",
      "    reask=None,\n",
      "    validation_passed=True,\n",
      "    error=None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from guardrails import Guard\n",
    "from guardrails.hub import DetectPII\n",
    "\n",
    "g = Guard(name=\"pii_guard\").use(DetectPII([\"PERSON\", \"EMAIL_ADDRESS\"], on_fail=\"fix\"))\n",
    "\n",
    "print(g.validate(\"My name is John Doe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0725d977f5589b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Guardrails Configuration \n",
    "\n",
    "Now we'll use the Guard we defeined above to create an action and a flow. Since we're calling our guard \"pii_guard\", we'll use \"pii_guard_validate\" in order to see if the LLM output is safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27c15cf3919fa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:27:13.820255Z",
     "start_time": "2024-01-25T14:27:13.814191Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config/rails.co\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/rails.co\n",
    "\n",
    "\n",
    "define flow detect_pii\n",
    "  $output = execute pii_guard_validate(text=$bot_message)\n",
    "\n",
    "  if not $output\n",
    "    bot refuse to respond\n",
    "    stop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53403afb1e1a4b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:27:13.821992Z",
     "start_time": "2024-01-25T14:27:13.817004Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config/config.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/config.yml\n",
    "models:\n",
    " - type: main\n",
    "   engine: openai\n",
    "   model: gpt-3.5-turbo-instruct\n",
    "\n",
    "rails:\n",
    "  output:\n",
    "    flows:\n",
    "      - detect_pii"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b3725",
   "metadata": {},
   "source": [
    "To hook the Guardrails AI guard up so that it can be read from Colang, we use the integration's `register_guardrails_guard_actions` function.\n",
    "This takes a name and registers two actions:\n",
    "\n",
    "1. [guard_name]_validate: This action is used to detect validation failures in outputs\n",
    "2. [guard name]_fix: This action is used to automatically fix validation failures in outputs, when possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2adca21d94e54b9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|██████████| 5/5 [00:00<00:00, 109226.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from nemoguardrails import RailsConfig, LLMRails\n",
    "from nemoguardrails.integrations.guardrails_ai.guard_actions import register_guardrails_guard_actions\n",
    "\n",
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "register_guardrails_guard_actions(rails, g, \"pii_guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade12682dd9d8f0e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Testing\n",
    "\n",
    "Let's try this out. If we invoke the guardrails configuration with a message that prompts the LLM to return personal information like names, email addresses, etc., it should refuse to respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394311174e678d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:27:18.524958Z",
     "start_time": "2024-01-25T14:27:18.518176Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I can't respond to that.\n"
     ]
    }
   ],
   "source": [
    "response = rails.generate(\"Who is the current president of the United States, and what was their email address?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d545fa7",
   "metadata": {},
   "source": [
    "Great! So the valdiation-only flow works.  Next let's try the fix flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62bac8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config/rails.co\n"
     ]
    }
   ],
   "source": [
    "%%writefile config/rails.co\n",
    "\n",
    "\n",
    "define flow detect_pii\n",
    "  $output = execute pii_guard_fix(text=$bot_message)\n",
    "\n",
    "  if not $output\n",
    "    bot refuse to respond\n",
    "    stop\n",
    "  else\n",
    "    $bot_message = $output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6d051",
   "metadata": {},
   "source": [
    "If we send the same message, we should get a response this time, but any PII will be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff14d3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current president of the United States is <PERSON>. His official email address is <EMAIL_ADDRESS>. However, he also has a personal email address, which is <EMAIL_ADDRESS>.\n"
     ]
    }
   ],
   "source": [
    "config = RailsConfig.from_path(\"./config\")\n",
    "rails = LLMRails(config)\n",
    "\n",
    "register_guardrails_guard_actions(rails, g, \"pii_guard\")\n",
    "\n",
    "response = rails.generate(\"Who is the current president of the United States, and what was their email address?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b457ce6e2957fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If however, we prompt the LLM with a message that does not cause it to return PII, we should get the unaltered response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70409a3aafe89e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-25T14:29:15.370273Z",
     "start_time": "2024-01-25T14:29:14.322661Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I assist you?\n"
     ]
    }
   ],
   "source": [
    "response = rails.generate(\"Hello!\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
